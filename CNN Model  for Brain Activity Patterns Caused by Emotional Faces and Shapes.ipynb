{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ph4aDDpcKcv"
      },
      "source": [
        Change Colab Settings<br>\n",
        "**Runtime --> Change Runtime Type --> Hardware accelerator: T4 GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgDKPn2Ias_S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6LA1glGke1c",
        "outputId": "b800d8ae-1bfa-49dd-dbdc-c823269fd50c"
      },
      "outputs": [],
      "source": [
        "# Mount Google drive\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "gdrive_dir = 'ARIN0707_project'\n",
        "\n",
        "if not os.path.exists('/content/drive/My Drive/' + gdrive_dir):\n",
        "  os.makedirs('/content/drive/My Drive/' + gdrive_dir)\n",
        "\n",
        "os.chdir('/content/drive/My Drive/' + gdrive_dir)\n",
        "\n",
        "data_path = '/content/drive/My Drive/' + gdrive_dir\n",
        "\n",
        "print(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXFXbdUcc1kN",
        "outputId": "4b26c505-e3a2-4b46-c0fe-27e05d8f94db"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "# You must have at least 5GB free space to download the dataset in your Google Drive\n",
        "# Check your Google Drive after download is done\n",
        "\n",
        "# Once you downloaded the dataset, you don't need to run this cell\n",
        "\n",
        "\n",
        "if not os.path.exists(data_path + '/HCP_emotion_4D_sample.mat'):\n",
        "  !pip install pydrive\n",
        "  print('\\n\\n')\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  gdrive = GoogleDrive(gauth)\n",
        "\n",
        "  # Download the data with Google Drive link\n",
        "  # Download takes about 5 mins.\n",
        "  img_file = gdrive.CreateFile({'id':'13p8oH6uulUoX9R4GwP1p3pUp7sFdlcby'})\n",
        "  img_file.GetContentFile(data_path + '/HCP_emotion_4D_sample.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga9i6D3lgNlO",
        "outputId": "44076988-aead-48a0-dff0-0655248141f3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from scipy.io import loadmat\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)   # change runtime type to \"T4 GPU\" if python print \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ6wdmgOfWzY"
      },
      "outputs": [],
      "source": [
        "# Load Data from Google Drive\n",
        "# You can load whole dataset, or split the dataset into individual 3D volumes and then load them with custom dataloader.\n",
        "\n",
        "data = loadmat(data_path + '/HCP_emotion_4D_sample.mat')\n",
        "\n",
        "# Train: 3200, Test: 800\n",
        "# Report your model's performance only on designated testset (800 samples)\n",
        "# You are not allowed to mix data samples between the predefined train / test datasets.\n",
        "\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "ids_train = data['ids_train']\n",
        "\n",
        "X_test = data['X_test']\n",
        "y_test = data['y_test']\n",
        "ids_test = data['ids_test']\n",
        "\n",
        "del data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBz1XA7tpt8C",
        "outputId": "d2ea13a0-1ae8-40fc-8f67-ea4a3fc5c71d"
      },
      "outputs": [],
      "source": [
        "# Check data shape\n",
        "\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('y_train shape: ', y_train.shape)\n",
        "print('ids_train shape: ', ids_train.shape)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print('X_test shape: ', X_test.shape)\n",
        "print('y_test shape: ', y_test.shape)\n",
        "print('ids_test shape: ', ids_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "AGiYrQrTiQWy",
        "outputId": "dcbda534-ce77-4b1d-d7cf-6e35fd6f9a30"
      },
      "outputs": [],
      "source": [
        "# Visualization for a sample data\n",
        "\n",
        "row = 5\n",
        "col = 9\n",
        "\n",
        "arr = X_train[0,:,:,:]\n",
        "fig, axes = plt.subplots(nrows=row, ncols=col)\n",
        "for order, ax in enumerate(axes.flat):\n",
        "\n",
        "  if order == arr.shape[-1] or order == row*col:\n",
        "    break\n",
        "\n",
        "  im = ax.imshow(arr[:,:,order])\n",
        "  ax.axis('off')\n",
        "\n",
        "for ax in axes.flat[order:]:\n",
        "    ax.remove()\n",
        "fig.subplots_adjust(right=0.8)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqLsr7WkrS4E",
        "outputId": "9b0ad203-b7eb-45a8-d1aa-92d284bf2ce1"
      },
      "outputs": [],
      "source": [
        "print('mean: ', np.mean(arr))\n",
        "print('max: ', np.max(arr))\n",
        "print('min: ', np.min(arr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJNPU0hFvVep",
        "outputId": "b5cff843-5f89-4d78-efe3-74647494a239"
      },
      "outputs": [],
      "source": [
        "arr = X_train[153,:,:,:]\n",
        "new_arr = np.where(arr!=0, arr, 0)\n",
        "print(np.count_nonzero(new_arr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AOChirgta0I"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "num_classes = 2\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.00001\n",
        "n_node = 3360"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThQ2WHTEtrNP"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes, n_node):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv3d(1, 4, kernel_size=3, stride=1, padding=1)   # 16\n",
        "        self.bn1 = nn.BatchNorm3d(4)\n",
        "        self.conv2 = nn.Conv3d(4, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(8)\n",
        "        self.conv3 = nn.Conv3d(8, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm3d(16)\n",
        "        self.conv4 = nn.Conv3d(16, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm3d(16)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_node, 100)  #\n",
        "        self.drop = nn.Dropout(p=0.1)\n",
        "        self.fc2 = nn.Linear(100, num_classes)\n",
        "\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        self.pool2 = nn.AvgPool3d(kernel_size=2, stride=2)\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = x.reshape(x.size(0),-1)\n",
        "        fcx1 = self.fc1(x)\n",
        "        dropx = self.drop(fcx1)\n",
        "        fcx2 = self.fc2(fcx1)\n",
        "\n",
        "        return fcx2\n",
        "\n",
        "model = CNN(num_classes, n_node=n_node).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# scheduler\n",
        "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max= num_epochs*0.2, eta_min=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "p1QfG9CDt1t7",
        "outputId": "25aa75d6-0775-41a3-fb2a-882ac1b39e80"
      },
      "outputs": [],
      "source": [
        "# Splitting Dataset\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "train_data = Dataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
        "test_data = Dataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))\n",
        "\n",
        "del X_train, y_train, X_test, y_test\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers = 8)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEWfU9xBygca",
        "outputId": "33b9365f-69d6-492e-d461-508b1faf44ca"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "best_acc = 0.0\n",
        "total_step = len(train_loader)\n",
        "\n",
        "# Training the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    for i, (images, labels) in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images.unsqueeze(1))\n",
        "        loss = criterion(outputs, labels.squeeze(1))\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        # Track the accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.squeeze(1)).sum().item()\n",
        "\n",
        "        pbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "    train_accuracy.append(correct / total * 100)\n",
        "    print(f'Train Accuracy of the model on the train: {train_accuracy[-1]}%')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images.unsqueeze(1))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.squeeze(1)).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "\n",
        "    loss = criterion(outputs, labels.squeeze(1))\n",
        "    test_losses.append(loss.item())\n",
        "    test_accuracy.append(correct / total * 100)\n",
        "\n",
        "    print('Test Accuracy of the model on the test: %f %% ' % (100 * correct / total))\n",
        "    print('--------------------------------------------------------')\n",
        "\n",
        "# # Save the model checkpoint\n",
        "\n",
        "# PATH = f'{data_path}/{best_acc:.4f}.ckpt'\n",
        "# torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA-wEKmv3YTY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
